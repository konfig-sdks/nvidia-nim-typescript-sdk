/* tslint:disable */
/* eslint-disable */
/*
Earth-2 Inference Server

API for submitting to the Earth-2 Inference Server.

The version of the OpenAPI document: 0.1.0
Contact: earth2-support@exchange.nvidia.com

NOTE: This file is auto generated by Konfig (https://konfigthis.com).
*/

import globalAxios, { AxiosPromise, AxiosInstance, AxiosRequestConfig } from 'axios';
import { Configuration } from '../configuration';
// Some imports not used depending on template conditions
// @ts-ignore
import { DUMMY_BASE_URL, assertParamExists, setApiKeyToObject, setBasicAuthToObject, setBearerAuthToObject, setSearchParams, serializeDataIfNeeded, toPathString, createRequestFunction, isBrowser } from '../common';
// @ts-ignore
import { BASE_PATH, COLLECTION_FORMATS, RequestArgs, BaseAPI, RequiredError } from '../base';
// @ts-ignore
import { ChatCompletionRequest } from '../models';
// @ts-ignore
import { ChatCompletionResponse } from '../models';
// @ts-ignore
import { HTTPValidationError } from '../models';
// @ts-ignore
import { MessagesProperty } from '../models';
// @ts-ignore
import { Null } from '../models';
// @ts-ignore
import { PaymentRequiredError } from '../models';
// @ts-ignore
import { StopProperty } from '../models';
import { paginate } from "../pagination/paginate";
import type * as buffer from "buffer"
import { requestBeforeHook } from '../requestBeforeHook';
/**
 * ChatApi - axios parameter creator
 * @export
 */
export const ChatApiAxiosParamCreator = function (configuration?: Configuration) {
    return {
        /**
         * Given a list of messages comprising a conversation, the model will return a response. Compatible with OpenAI. See https://platform.openai.com/docs/api-reference/chat/create
         * @summary Creates a model response for the given chat conversation.
         * @param {ChatCompletionRequest} chatCompletionRequest 
         * @param {*} [options] Override http request option.
         * @throws {RequiredError}
         */
        generateModelResponse: async (chatCompletionRequest: ChatCompletionRequest, options: AxiosRequestConfig = {}): Promise<RequestArgs> => {
            // verify required parameter 'chatCompletionRequest' is not null or undefined
            assertParamExists('generateModelResponse', 'chatCompletionRequest', chatCompletionRequest)
            const localVarPath = `/chat/completions`;
            // use dummy base URL string because the URL constructor only accepts absolute URLs.
            const localVarUrlObj = new URL(localVarPath, DUMMY_BASE_URL);
            let baseOptions;
            if (configuration) {
                baseOptions = configuration.baseOptions;
            }

            const localVarRequestOptions: AxiosRequestConfig = { method: 'POST', ...baseOptions, ...options};
            const localVarHeaderParameter = configuration && !isBrowser() ? { "User-Agent": configuration.userAgent } : {} as any;
            const localVarQueryParameter = {} as any;

            // authentication bearerAuth required
            // http bearer authentication required
            await setBearerAuthToObject(localVarHeaderParameter, configuration)

    
            localVarHeaderParameter['Content-Type'] = 'application/json';


            let headersFromBaseOptions = baseOptions && baseOptions.headers ? baseOptions.headers : {};
            localVarRequestOptions.headers = {...localVarHeaderParameter, ...headersFromBaseOptions, ...options.headers};
            requestBeforeHook({
                requestBody: chatCompletionRequest,
                queryParameters: localVarQueryParameter,
                requestConfig: localVarRequestOptions,
                path: localVarPath,
                configuration,
                pathTemplate: '/chat/completions',
                httpMethod: 'POST'
            });
            localVarRequestOptions.data = serializeDataIfNeeded(chatCompletionRequest, localVarRequestOptions, configuration)

            setSearchParams(localVarUrlObj, localVarQueryParameter);
            return {
                url: toPathString(localVarUrlObj),
                options: localVarRequestOptions,
            };
        },
    }
};

/**
 * ChatApi - functional programming interface
 * @export
 */
export const ChatApiFp = function(configuration?: Configuration) {
    const localVarAxiosParamCreator = ChatApiAxiosParamCreator(configuration)
    return {
        /**
         * Given a list of messages comprising a conversation, the model will return a response. Compatible with OpenAI. See https://platform.openai.com/docs/api-reference/chat/create
         * @summary Creates a model response for the given chat conversation.
         * @param {ChatApiGenerateModelResponseRequest} requestParameters Request parameters.
         * @param {*} [options] Override http request option.
         * @throws {RequiredError}
         */
        async generateModelResponse(requestParameters: ChatApiGenerateModelResponseRequest, options?: AxiosRequestConfig): Promise<(axios?: AxiosInstance, basePath?: string) => AxiosPromise<ChatCompletionResponse>> {
            const chatCompletionRequest: ChatCompletionRequest = {
                model: requestParameters.model,
                max_tokens: requestParameters.max_tokens,
                stream: requestParameters.stream,
                temperature: requestParameters.temperature,
                top_p: requestParameters.top_p,
                stop: requestParameters.stop,
                frequency_penalty: requestParameters.frequency_penalty,
                presence_penalty: requestParameters.presence_penalty,
                seed: requestParameters.seed,
                messages: requestParameters.messages
            };
            const localVarAxiosArgs = await localVarAxiosParamCreator.generateModelResponse(chatCompletionRequest, options);
            return createRequestFunction(localVarAxiosArgs, globalAxios, BASE_PATH, configuration);
        },
    }
};

/**
 * ChatApi - factory interface
 * @export
 */
export const ChatApiFactory = function (configuration?: Configuration, basePath?: string, axios?: AxiosInstance) {
    const localVarFp = ChatApiFp(configuration)
    return {
        /**
         * Given a list of messages comprising a conversation, the model will return a response. Compatible with OpenAI. See https://platform.openai.com/docs/api-reference/chat/create
         * @summary Creates a model response for the given chat conversation.
         * @param {ChatApiGenerateModelResponseRequest} requestParameters Request parameters.
         * @param {*} [options] Override http request option.
         * @throws {RequiredError}
         */
        generateModelResponse(requestParameters: ChatApiGenerateModelResponseRequest, options?: AxiosRequestConfig): AxiosPromise<ChatCompletionResponse> {
            return localVarFp.generateModelResponse(requestParameters, options).then((request) => request(axios, basePath));
        },
    };
};

/**
 * Request parameters for generateModelResponse operation in ChatApi.
 * @export
 * @interface ChatApiGenerateModelResponseRequest
 */
export type ChatApiGenerateModelResponseRequest = {
    
} & ChatCompletionRequest

/**
 * ChatApiGenerated - object-oriented interface
 * @export
 * @class ChatApiGenerated
 * @extends {BaseAPI}
 */
export class ChatApiGenerated extends BaseAPI {
    /**
     * Given a list of messages comprising a conversation, the model will return a response. Compatible with OpenAI. See https://platform.openai.com/docs/api-reference/chat/create
     * @summary Creates a model response for the given chat conversation.
     * @param {ChatApiGenerateModelResponseRequest} requestParameters Request parameters.
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof ChatApiGenerated
     */
    public generateModelResponse(requestParameters: ChatApiGenerateModelResponseRequest, options?: AxiosRequestConfig) {
        return ChatApiFp(this.configuration).generateModelResponse(requestParameters, options).then((request) => request(this.axios, this.basePath));
    }
}
